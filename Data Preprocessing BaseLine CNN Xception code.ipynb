{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brMG53za4lDh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yrY8Nl_-DsBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HDqZzFJDsDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jRj2MvQI1jt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E8j75Oqds2f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auldvAl8wrxq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikUOtNzHJ099",
        "outputId": "4837191b-c165-4cf6-cdee-3d74f8787c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Default title text\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gao5quVroGr2"
      },
      "outputs": [],
      "source": [
        "data_dir =os.getcwd()+\"/drive/MyDrive/Ham10000/All_Images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WObVQ4Sdmw6"
      },
      "outputs": [],
      "source": [
        "dest_dir = os.getcwd() + \"/drive/MyDrive/Ham10000/Reorganized\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAwG7MEroGMg"
      },
      "outputs": [],
      "source": [
        "skin_df = pd.read_csv(\"/content/drive/MyDrive/Ham10000/HAM10000_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0dqbo9dZd9L",
        "outputId": "c48f1bb7-7c7e-4738-ecfe-1ea5513c8231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nv       6705\n",
            "mel      1113\n",
            "bkl      1099\n",
            "bcc       514\n",
            "akiec     327\n",
            "vasc      142\n",
            "df        115\n",
            "Name: dx, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(skin_df2['dx'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CHXT78ucQqU"
      },
      "outputs": [],
      "source": [
        "label=skin_df2['dx'].unique().tolist() #Extract Labels into a list\n",
        "label_images = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nmdRqbfZeAj"
      },
      "outputs": [],
      "source": [
        "for i in label:\n",
        "    os.mkdir(dest_dir + str(i)  + \"/\")\n",
        "    sample = skin_df2[skin_df2['dx'] == i]['image_id']\n",
        "    label_images.extend(sample)\n",
        "    for id in label_images:\n",
        "        shutil.copyfile((data_dir + \"/\"+ id +\".jpg\"), (dest_dir + i + \"/\"+id+\".jpg\"))\n",
        "    label_images=[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "\n",
        "# Construct an instance of the ImageDataGenerator class\n",
        "# Pass the augmentation parameters through the constructor. \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                                   featurewise_center=False, \n",
        "                                    samplewise_center=False, \n",
        "                                    featurewise_std_normalization=False, \n",
        "                                    samplewise_std_normalization=False, \n",
        "                                    zca_whitening=False, \n",
        "                                    zca_epsilon=1e-06, \n",
        "                                    rotation_range=20, \n",
        "                                    width_shift_range=0.2, \n",
        "                                    height_shift_range=0.2, \n",
        "                                    brightness_range=None, \n",
        "                                    shear_range=0.1, \n",
        "                                    zoom_range=0.1, \n",
        "                                    channel_shift_range=0.1, \n",
        "                                    fill_mode='nearest', \n",
        "                                    cval=0.0, \n",
        "                                    horizontal_flip=False, \n",
        "                                    vertical_flip=False, \n",
        "                                    rescale=None, \n",
        "                                    preprocessing_function=None, \n",
        "                                    data_format='channels_last', \n",
        "                                    validation_split=0.0, \n",
        "                                    interpolation_order=1, \n",
        "                                    dtype='float32')"
      ],
      "metadata": {
        "id": "Yit4yaEkDsHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = 'C://Users//VIRGIL//anaconda34//Reorganized//bcc//'\n",
        "\n",
        "dataset = []\n",
        "\n",
        "my_images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(my_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = io.imread(image_directory + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((600,450))\n",
        "        dataset.append(np.array(image))\n",
        "\n",
        "x = np.array(dataset)"
      ],
      "metadata": {
        "id": "dw86O_owEG_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=16,  \n",
        "                          save_to_dir='C://Users//VIRGIL//anaconda34//augmentedbcc', \n",
        "                          save_prefix='aug', \n",
        "                          save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i >= 53:\n",
        "        break"
      ],
      "metadata": {
        "id": "rJ1AvdwaEHIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SeM7nQVfEHO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = 'C://Users//VIRGIL//anaconda34//Reorganized//vasc//'\n",
        "\n",
        "dataset = []\n",
        "\n",
        "my_images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(my_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = io.imread(image_directory + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((600,450))\n",
        "        dataset.append(np.array(image))\n",
        "\n",
        "x = np.array(dataset)"
      ],
      "metadata": {
        "id": "muHOi7PgEase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=16,  \n",
        "                          save_to_dir='C://Users//VIRGIL//anaconda34//augmentedvasc', \n",
        "                          save_prefix='aug', \n",
        "                          save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i >= 53:\n",
        "        break"
      ],
      "metadata": {
        "id": "Hjuq-yQ3Ease"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = 'C://Users//VIRGIL//anaconda34//Reorganized//akiec//'\n",
        "\n",
        "dataset = []\n",
        "\n",
        "my_images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(my_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = io.imread(image_directory + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((600,450))\n",
        "        dataset.append(np.array(image))\n",
        "\n",
        "x = np.array(dataset)"
      ],
      "metadata": {
        "id": "X3NHngLWEazr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=16,  \n",
        "                          save_to_dir='C://Users//VIRGIL//anaconda34//augmentedakiec', \n",
        "                          save_prefix='aug', \n",
        "                          save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i >= 53:\n",
        "        break"
      ],
      "metadata": {
        "id": "jl8S9dViEazr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = 'C://Users//VIRGIL//anaconda34//Reorganized//df//'\n",
        "\n",
        "dataset = []\n",
        "\n",
        "my_images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(my_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = io.imread(image_directory + image_name)\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "        image = image.resize((600,450))\n",
        "        dataset.append(np.array(image))\n",
        "\n",
        "x = np.array(dataset)"
      ],
      "metadata": {
        "id": "MpxTmM7qEa-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=16,  \n",
        "                          save_to_dir='C://Users//VIRGIL//anaconda34//augmenteddf', \n",
        "                          save_prefix='aug', \n",
        "                          save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i >= 53:\n",
        "        break"
      ],
      "metadata": {
        "id": "hZrEEDLNEa-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQxN0O_hEhiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3ftCzZB2NS2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "np.random.seed(123)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D25BbXYC2NWL",
        "outputId": "b827f450-210a-455b-f61b-d08cdcb489c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8015 images belonging to 7 classes.\n",
            "Found 2000 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "        \n",
        "        validation_split=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "       \"/content/drive/MyDrive/Ham10000/Reorganized\",  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "         subset='training' )  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "       \"/content/drive/MyDrive/Ham10000/Reorganized\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHKiLedf42Fq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.linalg_ops import norm_v2\n",
        "import glob\n",
        "akiec = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/akiec/*.*')\n",
        "bcc = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/bcc/*.*')\n",
        "bkl= glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/bkl/*.*')\n",
        "df = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/df/*.*')\n",
        "mel = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/mel/*.*')\n",
        "nv = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/nv/*.*')\n",
        "vasc = glob.glob('/content/drive/MyDrive/Ham10000/ReorganizeD/vasc/*.*')\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for i in akiec:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(0)\n",
        "for i in bcc:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(1)\n",
        "for i in bkl:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(2)\n",
        "for i in df:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(3)\n",
        "for i in mel:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(4)\n",
        "for i in nv:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(5)\n",
        "for i in vasc:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (256,256))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(6)\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9IQSqhzIPdn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAHBMhifOgqv",
        "outputId": "a69cc9a3-8ea1-4d3a-b25f-fd2bda84790f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7006"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYl6OgddSCjo",
        "outputId": "92fc48e2-43fa-4f22-de99-b5d5fdbfdbd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[230, 202, 216],\n",
              "         [231, 203, 215],\n",
              "         [236, 208, 220],\n",
              "         ...,\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208]],\n",
              "\n",
              "        [[230, 202, 216],\n",
              "         [231, 203, 215],\n",
              "         [236, 208, 220],\n",
              "         ...,\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208]],\n",
              "\n",
              "        [[230, 202, 216],\n",
              "         [231, 203, 215],\n",
              "         [236, 208, 220],\n",
              "         ...,\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208],\n",
              "         [230, 209, 208]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[231, 211, 210],\n",
              "         [233, 213, 212],\n",
              "         [234, 214, 213],\n",
              "         ...,\n",
              "         [231, 210, 229],\n",
              "         [231, 210, 229],\n",
              "         [231, 210, 229]],\n",
              "\n",
              "        [[229, 209, 210],\n",
              "         [227, 207, 208],\n",
              "         [230, 210, 211],\n",
              "         ...,\n",
              "         [231, 209, 230],\n",
              "         [231, 209, 230],\n",
              "         [231, 209, 230]],\n",
              "\n",
              "        [[227, 207, 206],\n",
              "         [226, 206, 205],\n",
              "         [227, 207, 206],\n",
              "         ...,\n",
              "         [234, 210, 232],\n",
              "         [234, 210, 232],\n",
              "         [235, 211, 233]]],\n",
              "\n",
              "\n",
              "       [[[200, 184, 184],\n",
              "         [199, 183, 183],\n",
              "         [199, 183, 183],\n",
              "         ...,\n",
              "         [186, 168, 168],\n",
              "         [186, 168, 166],\n",
              "         [187, 167, 166]],\n",
              "\n",
              "        [[199, 183, 183],\n",
              "         [198, 182, 182],\n",
              "         [200, 184, 184],\n",
              "         ...,\n",
              "         [191, 173, 173],\n",
              "         [190, 172, 170],\n",
              "         [190, 170, 169]],\n",
              "\n",
              "        [[198, 182, 182],\n",
              "         [199, 183, 183],\n",
              "         [201, 185, 185],\n",
              "         ...,\n",
              "         [191, 173, 173],\n",
              "         [190, 172, 170],\n",
              "         [192, 172, 171]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[197, 181, 181],\n",
              "         [195, 179, 179],\n",
              "         [197, 181, 181],\n",
              "         ...,\n",
              "         [182, 164, 164],\n",
              "         [180, 163, 156],\n",
              "         [181, 163, 159]],\n",
              "\n",
              "        [[196, 180, 180],\n",
              "         [195, 179, 179],\n",
              "         [195, 179, 179],\n",
              "         ...,\n",
              "         [182, 166, 166],\n",
              "         [182, 164, 160],\n",
              "         [183, 165, 161]],\n",
              "\n",
              "        [[195, 179, 179],\n",
              "         [195, 179, 179],\n",
              "         [195, 179, 179],\n",
              "         ...,\n",
              "         [187, 168, 170],\n",
              "         [185, 167, 163],\n",
              "         [184, 166, 162]]],\n",
              "\n",
              "\n",
              "       [[[221, 149, 153],\n",
              "         [217, 144, 151],\n",
              "         [224, 149, 156],\n",
              "         ...,\n",
              "         [211, 154, 163],\n",
              "         [210, 153, 162],\n",
              "         [209, 152, 161]],\n",
              "\n",
              "        [[222, 150, 154],\n",
              "         [220, 147, 154],\n",
              "         [225, 150, 157],\n",
              "         ...,\n",
              "         [211, 154, 161],\n",
              "         [212, 155, 162],\n",
              "         [212, 155, 162]],\n",
              "\n",
              "        [[222, 151, 155],\n",
              "         [223, 150, 157],\n",
              "         [225, 152, 159],\n",
              "         ...,\n",
              "         [204, 148, 151],\n",
              "         [207, 151, 154],\n",
              "         [210, 154, 157]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[224, 163, 171],\n",
              "         [223, 162, 167],\n",
              "         [220, 160, 162],\n",
              "         ...,\n",
              "         [179, 127, 139],\n",
              "         [178, 126, 138],\n",
              "         [177, 125, 137]],\n",
              "\n",
              "        [[225, 164, 172],\n",
              "         [222, 161, 166],\n",
              "         [219, 159, 161],\n",
              "         ...,\n",
              "         [173, 121, 133],\n",
              "         [175, 123, 135],\n",
              "         [177, 125, 137]],\n",
              "\n",
              "        [[223, 162, 167],\n",
              "         [225, 165, 167],\n",
              "         [214, 154, 154],\n",
              "         ...,\n",
              "         [169, 119, 128],\n",
              "         [170, 120, 129],\n",
              "         [169, 122, 132]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[214, 153, 168],\n",
              "         [217, 156, 171],\n",
              "         [221, 160, 175],\n",
              "         ...,\n",
              "         [214, 165, 195],\n",
              "         [210, 161, 191],\n",
              "         [204, 155, 184]],\n",
              "\n",
              "        [[214, 153, 168],\n",
              "         [217, 156, 171],\n",
              "         [221, 160, 175],\n",
              "         ...,\n",
              "         [213, 164, 194],\n",
              "         [209, 160, 190],\n",
              "         [204, 155, 184]],\n",
              "\n",
              "        [[215, 154, 169],\n",
              "         [218, 157, 172],\n",
              "         [222, 161, 176],\n",
              "         ...,\n",
              "         [213, 164, 194],\n",
              "         [208, 159, 189],\n",
              "         [203, 154, 183]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[245, 193, 206],\n",
              "         [245, 193, 206],\n",
              "         [246, 194, 207],\n",
              "         ...,\n",
              "         [212, 160, 173],\n",
              "         [208, 156, 169],\n",
              "         [184, 132, 145]],\n",
              "\n",
              "        [[245, 193, 206],\n",
              "         [244, 192, 205],\n",
              "         [244, 192, 205],\n",
              "         ...,\n",
              "         [205, 153, 165],\n",
              "         [207, 155, 167],\n",
              "         [196, 144, 156]],\n",
              "\n",
              "        [[254, 191, 210],\n",
              "         [247, 186, 202],\n",
              "         [247, 186, 202],\n",
              "         ...,\n",
              "         [208, 156, 178],\n",
              "         [204, 152, 174],\n",
              "         [196, 145, 164]]],\n",
              "\n",
              "\n",
              "       [[[222, 186, 198],\n",
              "         [222, 186, 198],\n",
              "         [222, 186, 198],\n",
              "         ...,\n",
              "         [220, 194, 203],\n",
              "         [221, 195, 204],\n",
              "         [222, 196, 205]],\n",
              "\n",
              "        [[221, 188, 199],\n",
              "         [221, 188, 199],\n",
              "         [221, 188, 199],\n",
              "         ...,\n",
              "         [220, 194, 203],\n",
              "         [221, 195, 204],\n",
              "         [221, 195, 204]],\n",
              "\n",
              "        [[218, 185, 196],\n",
              "         [218, 185, 196],\n",
              "         [218, 185, 196],\n",
              "         ...,\n",
              "         [219, 193, 202],\n",
              "         [220, 194, 203],\n",
              "         [221, 195, 204]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         ...,\n",
              "         [202, 154, 152],\n",
              "         [203, 155, 153],\n",
              "         [202, 154, 152]],\n",
              "\n",
              "        [[228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         ...,\n",
              "         [202, 154, 152],\n",
              "         [203, 155, 153],\n",
              "         [202, 154, 152]],\n",
              "\n",
              "        [[228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         [228, 208, 219],\n",
              "         ...,\n",
              "         [200, 155, 152],\n",
              "         [201, 156, 153],\n",
              "         [200, 155, 152]]],\n",
              "\n",
              "\n",
              "       [[[235, 204, 210],\n",
              "         [235, 204, 210],\n",
              "         [235, 204, 210],\n",
              "         ...,\n",
              "         [234, 197, 215],\n",
              "         [235, 198, 216],\n",
              "         [236, 199, 217]],\n",
              "\n",
              "        [[235, 204, 210],\n",
              "         [235, 204, 210],\n",
              "         [235, 204, 210],\n",
              "         ...,\n",
              "         [234, 197, 215],\n",
              "         [235, 198, 216],\n",
              "         [236, 199, 217]],\n",
              "\n",
              "        [[234, 203, 209],\n",
              "         [234, 203, 209],\n",
              "         [234, 203, 209],\n",
              "         ...,\n",
              "         [234, 197, 215],\n",
              "         [235, 198, 216],\n",
              "         [236, 199, 217]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[236, 195, 203],\n",
              "         [237, 194, 203],\n",
              "         [238, 192, 202],\n",
              "         ...,\n",
              "         [235, 203, 216],\n",
              "         [235, 203, 216],\n",
              "         [235, 203, 216]],\n",
              "\n",
              "        [[236, 193, 202],\n",
              "         [236, 193, 202],\n",
              "         [236, 190, 200],\n",
              "         ...,\n",
              "         [234, 203, 218],\n",
              "         [234, 203, 218],\n",
              "         [234, 203, 218]],\n",
              "\n",
              "        [[237, 192, 199],\n",
              "         [236, 189, 197],\n",
              "         [235, 188, 196],\n",
              "         ...,\n",
              "         [235, 201, 215],\n",
              "         [236, 202, 216],\n",
              "         [235, 201, 217]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJC2MWmd480-"
      },
      "outputs": [],
      "source": [
        "x_train = np.asarray(X_train)\n",
        "x_test = np.asarray(X_test)\n",
        "\n",
        "x_train_mean = np.mean(x_train)\n",
        "x_train_std = np.std(x_train)\n",
        "\n",
        "x_test_mean = np.mean(x_test)\n",
        "x_test_std = np.std(x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fFD2plmQjH7"
      },
      "outputs": [],
      "source": [
        "x_train = (x_train - x_train_mean)/x_train_std\n",
        "x_test = (x_test - x_test_mean)/x_test_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnpfv1m15Du1"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(ytrain, num_classes = 7)\n",
        "y_test = to_categorical(ytest, num_classes = 7)\n",
        "\n",
        "#Splitting training into Train and Validate sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9A7tsRGlZJNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7LqAQo_IZJS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70qzbzjNZJWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edUZVAqMZJlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx_train, xx_validate, yy_train, yy_validate = train_test_split(XX_train, y_train, test_size = 0.1)"
      ],
      "metadata": {
        "id": "ctOR57Z91_-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvmKOTXXkRcn"
      },
      "outputs": [],
      "source": [
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYBj0rbKIfo2"
      },
      "outputs": [],
      "source": [
        "\n",
        "np.save('/content/drive/MyDrive/SAVE/x_test.npy',XX_test)\n",
        "np.save('/content/drive/MyDrive/SAVE/y_test.npy', y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFHhrkjcbD7x"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/SAVE/y_train.npy', yy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2CbIDr4bKrB"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/SAVE/x_train.npy', xx_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr577inUbV9Q"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/SAVE/x_validate.npy', xx_validate)\n",
        "np.save('/content/drive/MyDrive/SAVE/y_validate.npy', yy_validate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLFq6GZuiSuQ",
        "outputId": "b63dec7c-535f-4127-e031-a1f44ff0be37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-1.07458726e-01, -1.09867565e+00, -9.44486355e-01],\n",
              "         [ 8.39704117e-01, -2.39620983e-01, -1.51512812e-01],\n",
              "         [ 1.05997455e+00, -8.54316834e-02, -4.13775977e-02],\n",
              "         ...,\n",
              "         [ 1.39038019e+00,  2.67001002e-01,  4.21190302e-01],\n",
              "         [ 1.39038019e+00,  2.67001002e-01,  4.21190302e-01],\n",
              "         [ 1.30227202e+00,  1.78892831e-01,  3.33082131e-01]],\n",
              "\n",
              "        [[-1.95566898e-01, -1.18678383e+00, -1.03259453e+00],\n",
              "         [ 8.61731160e-01, -1.51512812e-01, -8.54316834e-02],\n",
              "         [ 1.03794750e+00, -6.34046406e-02, -4.13775977e-02],\n",
              "         ...,\n",
              "         [ 1.30227202e+00,  1.78892831e-01,  3.77136217e-01],\n",
              "         [ 1.32429906e+00,  2.00919874e-01,  3.99163259e-01],\n",
              "         [ 1.28024497e+00,  1.56865788e-01,  3.55109174e-01]],\n",
              "\n",
              "        [[-2.39620983e-01, -1.18678383e+00, -9.88540441e-01],\n",
              "         [ 9.93893417e-01,  2.67648801e-03,  1.12811702e-01],\n",
              "         [ 1.08200159e+00,  2.47035309e-02,  2.47035309e-02],\n",
              "         ...,\n",
              "         [ 1.28024497e+00,  1.56865788e-01,  3.55109174e-01],\n",
              "         [ 1.28024497e+00,  1.56865788e-01,  3.55109174e-01],\n",
              "         [ 1.28024497e+00,  1.56865788e-01,  3.55109174e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         ...,\n",
              "         [ 1.23619089e+00,  1.56865788e-01,  4.67305737e-02],\n",
              "         [ 1.03794750e+00, -4.13775977e-02, -1.51512812e-01],\n",
              "         [ 9.93893417e-01, -8.54316834e-02, -1.73539855e-01]],\n",
              "\n",
              "        [[-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         ...,\n",
              "         [ 1.23619089e+00,  1.56865788e-01,  4.67305737e-02],\n",
              "         [ 1.05997455e+00, -1.93505548e-02, -1.29485769e-01],\n",
              "         [ 9.93893417e-01, -8.54316834e-02, -1.73539855e-01]],\n",
              "\n",
              "        [[-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         [-6.14080712e-01, -1.38502721e+00, -1.23083791e+00],\n",
              "         ...,\n",
              "         [ 1.28024497e+00,  2.00919874e-01,  1.12811702e-01],\n",
              "         [ 1.10402863e+00,  2.47035309e-02, -8.54316834e-02],\n",
              "         [ 1.01592046e+00, -4.13775977e-02, -2.61648026e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 5.53352559e-01, -6.80161841e-01, -6.14080712e-01],\n",
              "         [ 5.75379602e-01, -6.58134798e-01, -5.92053669e-01],\n",
              "         [ 5.97406645e-01, -6.36107755e-01, -5.70026626e-01],\n",
              "         ...,\n",
              "         [ 3.11055088e-01, -9.22459312e-01, -7.24215926e-01],\n",
              "         [ 2.89028045e-01, -9.44486355e-01, -7.46242969e-01],\n",
              "         [ 2.67001002e-01, -9.66513398e-01, -7.68270012e-01]],\n",
              "\n",
              "        [[ 5.97406645e-01, -7.02188883e-01, -6.14080712e-01],\n",
              "         [ 5.75379602e-01, -7.24215926e-01, -6.36107755e-01],\n",
              "         [ 5.75379602e-01, -7.24215926e-01, -6.36107755e-01],\n",
              "         ...,\n",
              "         [ 3.11055088e-01, -9.22459312e-01, -7.24215926e-01],\n",
              "         [ 2.89028045e-01, -9.44486355e-01, -7.46242969e-01],\n",
              "         [ 2.67001002e-01, -9.66513398e-01, -7.68270012e-01]],\n",
              "\n",
              "        [[ 6.85514817e-01, -6.58134798e-01, -5.47999583e-01],\n",
              "         [ 6.63487774e-01, -6.80161841e-01, -5.70026626e-01],\n",
              "         [ 6.41460731e-01, -7.02188883e-01, -5.92053669e-01],\n",
              "         ...,\n",
              "         [ 3.11055088e-01, -9.22459312e-01, -7.24215926e-01],\n",
              "         [ 2.89028045e-01, -9.44486355e-01, -7.46242969e-01],\n",
              "         [ 2.67001002e-01, -9.66513398e-01, -7.68270012e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 7.07541859e-01, -6.80161841e-01, -4.81918455e-01],\n",
              "         [ 7.29568902e-01, -6.58134798e-01, -4.59891412e-01],\n",
              "         [ 7.51595945e-01, -6.36107755e-01, -4.37864369e-01],\n",
              "         ...,\n",
              "         [ 6.87576166e-02, -9.44486355e-01, -9.44486355e-01],\n",
              "         [ 9.07846594e-02, -9.22459312e-01, -9.22459312e-01],\n",
              "         [ 9.07846594e-02, -9.22459312e-01, -9.22459312e-01]],\n",
              "\n",
              "        [[ 7.07541859e-01, -6.80161841e-01, -4.81918455e-01],\n",
              "         [ 7.29568902e-01, -6.58134798e-01, -4.59891412e-01],\n",
              "         [ 7.51595945e-01, -6.36107755e-01, -4.37864369e-01],\n",
              "         ...,\n",
              "         [ 2.22946917e-01, -7.90297055e-01, -7.90297055e-01],\n",
              "         [ 2.00919874e-01, -8.12324098e-01, -8.12324098e-01],\n",
              "         [ 1.78892831e-01, -8.34351141e-01, -8.34351141e-01]],\n",
              "\n",
              "        [[ 7.07541859e-01, -6.80161841e-01, -4.81918455e-01],\n",
              "         [ 7.29568902e-01, -6.58134798e-01, -4.59891412e-01],\n",
              "         [ 7.51595945e-01, -6.36107755e-01, -4.37864369e-01],\n",
              "         ...,\n",
              "         [ 2.89028045e-01, -7.02188883e-01, -7.68270012e-01],\n",
              "         [ 2.67001002e-01, -7.24215926e-01, -7.90297055e-01],\n",
              "         [ 2.44973959e-01, -7.46242969e-01, -8.12324098e-01]]],\n",
              "\n",
              "\n",
              "       [[[ 1.78892831e-01, -7.68270012e-01, -1.14272974e+00],\n",
              "         [ 6.63487774e-01, -9.44486355e-01, -1.14272974e+00],\n",
              "         [ 2.89028045e-01, -9.22459312e-01, -1.03259453e+00],\n",
              "         ...,\n",
              "         [-1.51512812e-01, -1.23083791e+00, -1.34097313e+00],\n",
              "         [-1.73539855e-01, -1.14272974e+00, -1.38502721e+00],\n",
              "         [-1.51512812e-01, -1.07664861e+00, -1.34097313e+00]],\n",
              "\n",
              "        [[ 6.19433688e-01, -1.12070270e+00, -1.05462157e+00],\n",
              "         [ 2.22946917e-01, -8.12324098e-01, -1.03259453e+00],\n",
              "         [ 5.09298474e-01, -7.46242969e-01, -9.44486355e-01],\n",
              "         ...,\n",
              "         [-1.95566898e-01, -1.18678383e+00, -1.29691904e+00],\n",
              "         [-1.73539855e-01, -1.14272974e+00, -1.38502721e+00],\n",
              "         [-1.51512812e-01, -1.07664861e+00, -1.34097313e+00]],\n",
              "\n",
              "        [[ 3.55109174e-01, -4.37864369e-01, -7.02188883e-01],\n",
              "         [ 5.75379602e-01, -5.47999583e-01, -6.14080712e-01],\n",
              "         [ 4.21190302e-01, -7.46242969e-01, -9.22459312e-01],\n",
              "         ...,\n",
              "         [-1.29485769e-01, -1.20881087e+00, -1.29691904e+00],\n",
              "         [-1.51512812e-01, -1.12070270e+00, -1.31894608e+00],\n",
              "         [-1.29485769e-01, -1.09867565e+00, -1.38502721e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 4.87271431e-01, -8.12324098e-01, -6.80161841e-01],\n",
              "         [ 5.09298474e-01, -8.34351141e-01, -6.58134798e-01],\n",
              "         [ 3.77136217e-01, -9.66513398e-01, -9.88540441e-01],\n",
              "         ...,\n",
              "         [-2.39620983e-01, -1.23083791e+00, -1.29691904e+00],\n",
              "         [-1.95566898e-01, -1.25286495e+00, -1.34097313e+00],\n",
              "         [-2.17593941e-01, -1.18678383e+00, -1.25286495e+00]],\n",
              "\n",
              "        [[ 4.21190302e-01, -7.46242969e-01, -8.78405226e-01],\n",
              "         [ 5.75379602e-01, -8.34351141e-01, -8.34351141e-01],\n",
              "         [ 4.43217345e-01, -9.22459312e-01, -1.16475678e+00],\n",
              "         ...,\n",
              "         [-1.73539855e-01, -1.23083791e+00, -1.27489200e+00],\n",
              "         [-1.95566898e-01, -1.25286495e+00, -1.29691904e+00],\n",
              "         [-2.17593941e-01, -1.20881087e+00, -1.27489200e+00]],\n",
              "\n",
              "        [[ 4.65244388e-01, -8.56378183e-01, -8.12324098e-01],\n",
              "         [ 4.43217345e-01, -6.58134798e-01, -8.12324098e-01],\n",
              "         [ 5.31325517e-01, -7.68270012e-01, -9.00432269e-01],\n",
              "         ...,\n",
              "         [-1.95566898e-01, -1.09867565e+00, -1.18678383e+00],\n",
              "         [-2.83675069e-01, -1.18678383e+00, -1.23083791e+00],\n",
              "         [-3.27729155e-01, -1.25286495e+00, -1.23083791e+00]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 1.01592046e+00, -9.66513398e-01, -7.68270012e-01],\n",
              "         [ 1.01592046e+00, -9.88540441e-01, -8.78405226e-01],\n",
              "         [-3.27729155e-01, -2.31016301e+00, -2.48637936e+00],\n",
              "         ...,\n",
              "         [ 1.12605567e+00, -7.68270012e-01, -5.25972541e-01],\n",
              "         [ 9.93893417e-01, -8.34351141e-01, -4.81918455e-01],\n",
              "         [ 9.05785245e-01, -1.01056748e+00, -6.58134798e-01]],\n",
              "\n",
              "        [[ 9.27812288e-01, -1.07664861e+00, -7.46242969e-01],\n",
              "         [ 9.27812288e-01, -1.05462157e+00, -8.56378183e-01],\n",
              "         [ 1.23619089e+00, -9.00432269e-01, -6.58134798e-01],\n",
              "         ...,\n",
              "         [ 1.08200159e+00, -9.66513398e-01, -5.03945498e-01],\n",
              "         [ 1.12605567e+00, -9.00432269e-01, -3.49756198e-01],\n",
              "         [ 1.03794750e+00, -9.66513398e-01, -5.70026626e-01]],\n",
              "\n",
              "        [[ 1.05997455e+00, -1.09867565e+00, -8.12324098e-01],\n",
              "         [ 9.71866374e-01, -1.05462157e+00, -7.68270012e-01],\n",
              "         [ 1.05997455e+00, -1.18678383e+00, -9.44486355e-01],\n",
              "         ...,\n",
              "         [ 1.08200159e+00, -9.44486355e-01, -4.37864369e-01],\n",
              "         [ 1.14808272e+00, -8.78405226e-01, -3.27729155e-01],\n",
              "         [ 1.01592046e+00, -9.00432269e-01, -5.25972541e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 6.63487774e-01, -1.12070270e+00, -1.20881087e+00],\n",
              "         [ 6.19433688e-01, -1.09867565e+00, -1.09867565e+00],\n",
              "         [ 7.07541859e-01, -1.14272974e+00, -1.14272974e+00],\n",
              "         ...,\n",
              "         [ 7.73622988e-01, -8.56378183e-01, -5.70026626e-01],\n",
              "         [ 7.73622988e-01, -8.78405226e-01, -4.37864369e-01],\n",
              "         [ 7.51595945e-01, -7.68270012e-01, -6.58134798e-01]],\n",
              "\n",
              "        [[ 5.53352559e-01, -1.20881087e+00, -1.23083791e+00],\n",
              "         [ 6.85514817e-01, -1.05462157e+00, -9.88540441e-01],\n",
              "         [ 7.51595945e-01, -1.01056748e+00, -1.03259453e+00],\n",
              "         ...,\n",
              "         [ 7.07541859e-01, -9.44486355e-01, -7.90297055e-01],\n",
              "         [ 7.73622988e-01, -7.68270012e-01, -5.92053669e-01],\n",
              "         [ 6.85514817e-01, -9.00432269e-01, -6.36107755e-01]],\n",
              "\n",
              "        [[ 7.07541859e-01, -1.01056748e+00, -1.01056748e+00],\n",
              "         [ 5.97406645e-01, -1.18678383e+00, -1.25286495e+00],\n",
              "         [ 6.63487774e-01, -1.09867565e+00, -1.07664861e+00],\n",
              "         ...,\n",
              "         [ 5.75379602e-01, -1.01056748e+00, -9.44486355e-01],\n",
              "         [ 6.63487774e-01, -9.44486355e-01, -7.02188883e-01],\n",
              "         [ 7.07541859e-01, -9.44486355e-01, -8.56378183e-01]]],\n",
              "\n",
              "\n",
              "       [[[-2.72867683e+00, -2.97097430e+00, -2.88286613e+00],\n",
              "         [-2.57448753e+00, -2.83881204e+00, -2.79475796e+00],\n",
              "         [-2.48637936e+00, -2.75070387e+00, -2.66259570e+00],\n",
              "         ...,\n",
              "         [-2.72867683e+00, -2.97097430e+00, -3.01502838e+00],\n",
              "         [-2.79475796e+00, -3.03705543e+00, -2.86083908e+00],\n",
              "         [-2.81678500e+00, -3.03705543e+00, -3.01502838e+00]],\n",
              "\n",
              "        [[-2.64056866e+00, -2.90489317e+00, -2.90489317e+00],\n",
              "         [-2.50840640e+00, -2.72867683e+00, -2.70664978e+00],\n",
              "         [-2.33219006e+00, -2.64056866e+00, -2.64056866e+00],\n",
              "         ...,\n",
              "         [-2.68462274e+00, -2.92692021e+00, -2.97097430e+00],\n",
              "         [-2.70664978e+00, -3.03705543e+00, -2.92692021e+00],\n",
              "         [-2.77273091e+00, -2.99300134e+00, -2.97097430e+00]],\n",
              "\n",
              "        [[-2.55246048e+00, -2.81678500e+00, -2.77273091e+00],\n",
              "         [-2.46435231e+00, -2.72867683e+00, -2.68462274e+00],\n",
              "         [-2.26610893e+00, -2.57448753e+00, -2.57448753e+00],\n",
              "         ...,\n",
              "         [-2.57448753e+00, -2.88286613e+00, -2.88286613e+00],\n",
              "         [-2.68462274e+00, -3.01502838e+00, -2.94894726e+00],\n",
              "         [-2.79475796e+00, -3.01502838e+00, -2.99300134e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.70664978e+00, -3.03705543e+00, -2.97097430e+00],\n",
              "         [-2.83881204e+00, -3.10313656e+00, -3.05908247e+00],\n",
              "         [-2.79475796e+00, -3.16921768e+00, -3.03705543e+00],\n",
              "         ...,\n",
              "         [-2.88286613e+00, -3.14719064e+00, -3.14719064e+00],\n",
              "         [-2.88286613e+00, -3.14719064e+00, -3.14719064e+00],\n",
              "         [-2.88286613e+00, -3.14719064e+00, -3.10313656e+00]],\n",
              "\n",
              "        [[-2.68462274e+00, -3.03705543e+00, -2.97097430e+00],\n",
              "         [-2.68462274e+00, -3.03705543e+00, -2.97097430e+00],\n",
              "         [-2.77273091e+00, -3.10313656e+00, -3.03705543e+00],\n",
              "         ...,\n",
              "         [-2.83881204e+00, -3.14719064e+00, -3.16921768e+00],\n",
              "         [-2.88286613e+00, -3.12516360e+00, -3.21327177e+00],\n",
              "         [-2.90489317e+00, -3.12516360e+00, -3.16921768e+00]],\n",
              "\n",
              "        [[-2.66259570e+00, -3.01502838e+00, -2.99300134e+00],\n",
              "         [-2.70664978e+00, -3.03705543e+00, -2.97097430e+00],\n",
              "         [-2.72867683e+00, -3.05908247e+00, -2.99300134e+00],\n",
              "         ...,\n",
              "         [-2.94894726e+00, -3.12516360e+00, -3.19124473e+00],\n",
              "         [-2.90489317e+00, -3.10313656e+00, -3.21327177e+00],\n",
              "         [-2.97097430e+00, -3.14719064e+00, -3.21327177e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 9.93893417e-01,  2.00919874e-01,  5.09298474e-01],\n",
              "         [ 9.93893417e-01,  1.56865788e-01,  4.43217345e-01],\n",
              "         [ 1.08200159e+00,  1.56865788e-01,  3.77136217e-01],\n",
              "         ...,\n",
              "         [ 1.08200159e+00,  2.00919874e-01,  3.99163259e-01],\n",
              "         [ 1.03794750e+00,  1.56865788e-01,  1.78892831e-01],\n",
              "         [ 9.27812288e-01,  2.67648801e-03,  2.47035309e-02]],\n",
              "\n",
              "        [[ 1.01592046e+00,  2.22946917e-01,  5.31325517e-01],\n",
              "         [ 1.01592046e+00,  1.78892831e-01,  4.65244388e-01],\n",
              "         [ 1.08200159e+00,  1.56865788e-01,  4.21190302e-01],\n",
              "         ...,\n",
              "         [ 1.01592046e+00,  2.00919874e-01,  3.77136217e-01],\n",
              "         [ 9.93893417e-01,  9.07846594e-02,  1.78892831e-01],\n",
              "         [ 1.01592046e+00,  9.07846594e-02,  1.12811702e-01]],\n",
              "\n",
              "        [[ 1.10402863e+00,  3.11055088e-01,  5.75379602e-01],\n",
              "         [ 1.03794750e+00,  2.00919874e-01,  4.87271431e-01],\n",
              "         [ 1.08200159e+00,  1.56865788e-01,  4.21190302e-01],\n",
              "         ...,\n",
              "         [ 1.10402863e+00,  2.44973959e-01,  3.55109174e-01],\n",
              "         [ 1.10402863e+00,  2.00919874e-01,  2.89028045e-01],\n",
              "         [ 1.08200159e+00,  1.56865788e-01,  2.44973959e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 8.61731160e-01, -5.47999583e-01, -5.92053669e-01],\n",
              "         [ 1.01592046e+00, -3.93810283e-01, -4.37864369e-01],\n",
              "         [ 9.49839331e-01, -4.59891412e-01, -5.03945498e-01],\n",
              "         ...,\n",
              "         [ 1.23619089e+00, -4.13775977e-02, -8.54316834e-02],\n",
              "         [ 9.93893417e-01, -4.15837326e-01, -6.36107755e-01],\n",
              "         [ 1.14808272e+00, -3.27729155e-01, -5.25972541e-01]],\n",
              "\n",
              "        [[ 8.17677074e-01, -5.70026626e-01, -6.80161841e-01],\n",
              "         [ 9.93893417e-01, -4.15837326e-01, -4.15837326e-01],\n",
              "         [ 9.27812288e-01, -4.81918455e-01, -5.25972541e-01],\n",
              "         ...,\n",
              "         [ 9.05785245e-01, -1.51512812e-01, -1.51512812e-01],\n",
              "         [ 8.39704117e-01, -3.71783241e-01, -4.37864369e-01],\n",
              "         [ 9.71866374e-01, -3.27729155e-01, -4.59891412e-01]],\n",
              "\n",
              "        [[ 7.95650031e-01, -5.92053669e-01, -7.02188883e-01],\n",
              "         [ 9.71866374e-01, -4.37864369e-01, -4.81918455e-01],\n",
              "         [ 9.93893417e-01, -4.15837326e-01, -4.59891412e-01],\n",
              "         ...,\n",
              "         [ 9.71866374e-01, -5.03945498e-01, -8.56378183e-01],\n",
              "         [ 9.93893417e-01, -5.03945498e-01, -9.66513398e-01],\n",
              "         [ 1.10402863e+00, -3.49756198e-01, -8.78405226e-01]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XX_train=X_train/255"
      ],
      "metadata": {
        "id": "YcsSeoeN0afs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbXEbJayiinI",
        "outputId": "6a9bfedd-3f84-4087-d88b-945446e18a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XX_test=X_test/255"
      ],
      "metadata": {
        "id": "xLw6aAy10wYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XX_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBu4K_Iz1Twp",
        "outputId": "f5bc5671-3028-43c7-9cf8-afa998d97a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.88235294, 0.66666667, 0.74117647],\n",
              "         [0.8745098 , 0.65882353, 0.73333333],\n",
              "         [0.87058824, 0.65490196, 0.72941176],\n",
              "         ...,\n",
              "         [0.85098039, 0.61568627, 0.65490196],\n",
              "         [0.84705882, 0.61176471, 0.65098039],\n",
              "         [0.83529412, 0.6       , 0.63921569]],\n",
              "\n",
              "        [[0.89803922, 0.6745098 , 0.74117647],\n",
              "         [0.89019608, 0.66666667, 0.73333333],\n",
              "         [0.88627451, 0.6627451 , 0.72941176],\n",
              "         ...,\n",
              "         [0.85098039, 0.61568627, 0.65490196],\n",
              "         [0.84705882, 0.61176471, 0.65098039],\n",
              "         [0.83137255, 0.59607843, 0.63529412]],\n",
              "\n",
              "        [[0.90196078, 0.67843137, 0.74509804],\n",
              "         [0.89803922, 0.6745098 , 0.74117647],\n",
              "         [0.89019608, 0.66666667, 0.73333333],\n",
              "         ...,\n",
              "         [0.84705882, 0.61176471, 0.65098039],\n",
              "         [0.84313725, 0.60784314, 0.64705882],\n",
              "         [0.83137255, 0.59607843, 0.63529412]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.91372549, 0.69019608, 0.74901961],\n",
              "         [0.90980392, 0.68235294, 0.74117647],\n",
              "         [0.89803922, 0.67058824, 0.72941176],\n",
              "         ...,\n",
              "         [0.87843137, 0.69411765, 0.75686275],\n",
              "         [0.88235294, 0.69803922, 0.76078431],\n",
              "         [0.88627451, 0.70196078, 0.76470588]],\n",
              "\n",
              "        [[0.91764706, 0.69411765, 0.75294118],\n",
              "         [0.90980392, 0.68235294, 0.74117647],\n",
              "         [0.89803922, 0.67058824, 0.72941176],\n",
              "         ...,\n",
              "         [0.87058824, 0.68627451, 0.74901961],\n",
              "         [0.8745098 , 0.69019608, 0.75294118],\n",
              "         [0.87843137, 0.69411765, 0.75686275]],\n",
              "\n",
              "        [[0.92941176, 0.69019608, 0.75294118],\n",
              "         [0.90588235, 0.66666667, 0.72941176],\n",
              "         [0.91372549, 0.6745098 , 0.7372549 ],\n",
              "         ...,\n",
              "         [0.8627451 , 0.67843137, 0.75686275],\n",
              "         [0.85882353, 0.6745098 , 0.75294118],\n",
              "         [0.8627451 , 0.67843137, 0.75686275]]],\n",
              "\n",
              "\n",
              "       [[[0.85882353, 0.5254902 , 0.49803922],\n",
              "         [0.8627451 , 0.52941176, 0.50196078],\n",
              "         [0.87058824, 0.5372549 , 0.50980392],\n",
              "         ...,\n",
              "         [0.96078431, 0.62352941, 0.57254902],\n",
              "         [0.91764706, 0.58039216, 0.52941176],\n",
              "         [0.91372549, 0.57647059, 0.5254902 ]],\n",
              "\n",
              "        [[0.8745098 , 0.54117647, 0.52156863],\n",
              "         [0.86666667, 0.53333333, 0.51372549],\n",
              "         [0.8627451 , 0.52941176, 0.50980392],\n",
              "         ...,\n",
              "         [0.95294118, 0.60784314, 0.56078431],\n",
              "         [0.9254902 , 0.58039216, 0.54117647],\n",
              "         [0.91764706, 0.57254902, 0.53333333]],\n",
              "\n",
              "        [[0.89019608, 0.55686275, 0.5372549 ],\n",
              "         [0.89019608, 0.55686275, 0.5372549 ],\n",
              "         [0.89019608, 0.55686275, 0.5372549 ],\n",
              "         ...,\n",
              "         [0.94117647, 0.59215686, 0.56078431],\n",
              "         [0.92941176, 0.58039216, 0.54901961],\n",
              "         [0.92156863, 0.57254902, 0.54901961]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         ...,\n",
              "         [0.85098039, 0.55294118, 0.45882353],\n",
              "         [0.85882353, 0.56078431, 0.46666667],\n",
              "         [0.84705882, 0.54901961, 0.45490196]],\n",
              "\n",
              "        [[0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         ...,\n",
              "         [0.84705882, 0.54117647, 0.45098039],\n",
              "         [0.83529412, 0.52941176, 0.43921569],\n",
              "         [0.82352941, 0.51764706, 0.42745098]],\n",
              "\n",
              "        [[0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         [0.86666667, 0.55686275, 0.49019608],\n",
              "         ...,\n",
              "         [0.84313725, 0.54509804, 0.45098039],\n",
              "         [0.84705882, 0.54901961, 0.45490196],\n",
              "         [0.83137255, 0.53333333, 0.44313725]]],\n",
              "\n",
              "\n",
              "       [[[0.7372549 , 0.60784314, 0.54901961],\n",
              "         [0.75294118, 0.59607843, 0.56470588],\n",
              "         [0.74117647, 0.59215686, 0.54901961],\n",
              "         ...,\n",
              "         [0.68235294, 0.52156863, 0.50588235],\n",
              "         [0.68235294, 0.50588235, 0.48627451],\n",
              "         [0.67843137, 0.50196078, 0.48235294]],\n",
              "\n",
              "        [[0.70980392, 0.55294118, 0.51372549],\n",
              "         [0.72156863, 0.54117647, 0.49019608],\n",
              "         [0.70980392, 0.55294118, 0.51372549],\n",
              "         ...,\n",
              "         [0.6745098 , 0.50196078, 0.50588235],\n",
              "         [0.6745098 , 0.49803922, 0.47843137],\n",
              "         [0.66666667, 0.49019608, 0.47843137]],\n",
              "\n",
              "        [[0.72156863, 0.60784314, 0.55294118],\n",
              "         [0.70588235, 0.54509804, 0.46666667],\n",
              "         [0.69803922, 0.54117647, 0.50980392],\n",
              "         ...,\n",
              "         [0.6627451 , 0.49019608, 0.49411765],\n",
              "         [0.68235294, 0.49411765, 0.47843137],\n",
              "         [0.64705882, 0.47058824, 0.45098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.74509804, 0.60784314, 0.58431373],\n",
              "         [0.74509804, 0.59215686, 0.56470588],\n",
              "         [0.7254902 , 0.58823529, 0.58039216],\n",
              "         ...,\n",
              "         [0.71372549, 0.6       , 0.61568627],\n",
              "         [0.72156863, 0.6       , 0.62352941],\n",
              "         [0.7254902 , 0.59607843, 0.62352941]],\n",
              "\n",
              "        [[0.7372549 , 0.58039216, 0.58431373],\n",
              "         [0.7372549 , 0.58431373, 0.58823529],\n",
              "         [0.72941176, 0.57254902, 0.57254902],\n",
              "         ...,\n",
              "         [0.71764706, 0.58823529, 0.61568627],\n",
              "         [0.7254902 , 0.58039216, 0.60784314],\n",
              "         [0.7254902 , 0.58823529, 0.61176471]],\n",
              "\n",
              "        [[0.72156863, 0.56078431, 0.5372549 ],\n",
              "         [0.72156863, 0.56078431, 0.5372549 ],\n",
              "         [0.7254902 , 0.56862745, 0.56862745],\n",
              "         ...,\n",
              "         [0.71372549, 0.57254902, 0.58823529],\n",
              "         [0.70588235, 0.55294118, 0.56470588],\n",
              "         [0.70980392, 0.54901961, 0.56470588]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.86666667, 0.70980392, 0.67843137],\n",
              "         [0.8627451 , 0.71372549, 0.67843137],\n",
              "         [0.85882353, 0.71372549, 0.67843137],\n",
              "         ...,\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ]],\n",
              "\n",
              "        [[0.86666667, 0.70980392, 0.67843137],\n",
              "         [0.8627451 , 0.71372549, 0.67843137],\n",
              "         [0.85882353, 0.71372549, 0.67843137],\n",
              "         ...,\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ]],\n",
              "\n",
              "        [[0.86666667, 0.70980392, 0.67843137],\n",
              "         [0.8627451 , 0.71372549, 0.67843137],\n",
              "         [0.85882353, 0.71372549, 0.67843137],\n",
              "         ...,\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ],\n",
              "         [0.78431373, 0.66666667, 0.6745098 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.79607843, 0.61960784, 0.5372549 ],\n",
              "         [0.81176471, 0.63529412, 0.56078431],\n",
              "         [0.81176471, 0.63529412, 0.56078431],\n",
              "         ...,\n",
              "         [0.80784314, 0.69411765, 0.70196078],\n",
              "         [0.80784314, 0.69411765, 0.70196078],\n",
              "         [0.80784314, 0.69411765, 0.70196078]],\n",
              "\n",
              "        [[0.79215686, 0.61568627, 0.5254902 ],\n",
              "         [0.80784314, 0.63137255, 0.54901961],\n",
              "         [0.81176471, 0.63529412, 0.55294118],\n",
              "         ...,\n",
              "         [0.80784314, 0.69803922, 0.69411765],\n",
              "         [0.80784314, 0.69803922, 0.69411765],\n",
              "         [0.80784314, 0.69803922, 0.69411765]],\n",
              "\n",
              "        [[0.8       , 0.60784314, 0.54117647],\n",
              "         [0.8       , 0.61568627, 0.54509804],\n",
              "         [0.80784314, 0.62352941, 0.55294118],\n",
              "         ...,\n",
              "         [0.80392157, 0.68627451, 0.67843137],\n",
              "         [0.80784314, 0.69019608, 0.68235294],\n",
              "         [0.81176471, 0.69411765, 0.68627451]]],\n",
              "\n",
              "\n",
              "       [[[0.83529412, 0.47843137, 0.46666667],\n",
              "         [0.81960784, 0.4627451 , 0.45098039],\n",
              "         [0.80784314, 0.45882353, 0.44313725],\n",
              "         ...,\n",
              "         [0.82745098, 0.48235294, 0.47843137],\n",
              "         [0.83529412, 0.49019608, 0.48627451],\n",
              "         [0.83921569, 0.48235294, 0.50196078]],\n",
              "\n",
              "        [[0.83921569, 0.47058824, 0.4745098 ],\n",
              "         [0.82745098, 0.4745098 , 0.48235294],\n",
              "         [0.83137255, 0.4745098 , 0.4627451 ],\n",
              "         ...,\n",
              "         [0.82745098, 0.47058824, 0.45882353],\n",
              "         [0.85098039, 0.49803922, 0.49411765],\n",
              "         [0.84705882, 0.50196078, 0.48627451]],\n",
              "\n",
              "        [[0.83529412, 0.46666667, 0.46666667],\n",
              "         [0.83137255, 0.48235294, 0.46666667],\n",
              "         [0.83529412, 0.47843137, 0.46666667],\n",
              "         ...,\n",
              "         [0.84313725, 0.48627451, 0.48235294],\n",
              "         [0.8627451 , 0.49019608, 0.51372549],\n",
              "         [0.84705882, 0.48627451, 0.49019608]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.75294118, 0.42745098, 0.39607843],\n",
              "         [0.75294118, 0.43137255, 0.38431373],\n",
              "         [0.74509804, 0.43529412, 0.38431373],\n",
              "         ...,\n",
              "         [0.75294118, 0.41568627, 0.35686275],\n",
              "         [0.72156863, 0.41176471, 0.34509804],\n",
              "         [0.72941176, 0.41176471, 0.3372549 ]],\n",
              "\n",
              "        [[0.74901961, 0.40784314, 0.36862745],\n",
              "         [0.74509804, 0.40392157, 0.36862745],\n",
              "         [0.77647059, 0.43529412, 0.39607843],\n",
              "         ...,\n",
              "         [0.74117647, 0.44313725, 0.38039216],\n",
              "         [0.74509804, 0.43529412, 0.37647059],\n",
              "         [0.74117647, 0.42352941, 0.34901961]],\n",
              "\n",
              "        [[0.7372549 , 0.42352941, 0.38039216],\n",
              "         [0.75686275, 0.42745098, 0.38823529],\n",
              "         [0.74901961, 0.43529412, 0.39215686],\n",
              "         ...,\n",
              "         [0.78823529, 0.44705882, 0.40784314],\n",
              "         [0.76470588, 0.4627451 , 0.4       ],\n",
              "         [0.74901961, 0.45490196, 0.37254902]]],\n",
              "\n",
              "\n",
              "       [[[0.        , 0.        , 0.00784314],\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.        ],\n",
              "         ...,\n",
              "         [0.03921569, 0.04313725, 0.02352941],\n",
              "         [0.03137255, 0.03137255, 0.03137255],\n",
              "         [0.02745098, 0.02352941, 0.01568627]],\n",
              "\n",
              "        [[0.00392157, 0.00392157, 0.01176471],\n",
              "         [0.00784314, 0.00784314, 0.00784314],\n",
              "         [0.00784314, 0.00784314, 0.        ],\n",
              "         ...,\n",
              "         [0.04313725, 0.04313725, 0.04313725],\n",
              "         [0.03529412, 0.03529412, 0.02745098],\n",
              "         [0.03137255, 0.03137255, 0.03137255]],\n",
              "\n",
              "        [[0.00392157, 0.00392157, 0.        ],\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.        ],\n",
              "         ...,\n",
              "         [0.03529412, 0.03921569, 0.01960784],\n",
              "         [0.03921569, 0.03921569, 0.03137255],\n",
              "         [0.03137255, 0.03137255, 0.02352941]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.05098039, 0.05098039, 0.05098039],\n",
              "         [0.05490196, 0.05490196, 0.04705882],\n",
              "         [0.0627451 , 0.05882353, 0.05098039],\n",
              "         ...,\n",
              "         [0.02352941, 0.02352941, 0.02352941],\n",
              "         [0.01568627, 0.01960784, 0.        ],\n",
              "         [0.01960784, 0.01960784, 0.01960784]],\n",
              "\n",
              "        [[0.04705882, 0.04705882, 0.04705882],\n",
              "         [0.0627451 , 0.05490196, 0.05882353],\n",
              "         [0.06666667, 0.05098039, 0.05490196],\n",
              "         ...,\n",
              "         [0.01960784, 0.02352941, 0.00392157],\n",
              "         [0.01960784, 0.01960784, 0.01960784],\n",
              "         [0.00784314, 0.00784314, 0.        ]],\n",
              "\n",
              "        [[0.04313725, 0.04313725, 0.04313725],\n",
              "         [0.05490196, 0.05490196, 0.05490196],\n",
              "         [0.04705882, 0.04705882, 0.03921569],\n",
              "         ...,\n",
              "         [0.01568627, 0.01568627, 0.00784314],\n",
              "         [0.01568627, 0.01568627, 0.00784314],\n",
              "         [0.01176471, 0.01176471, 0.00392157]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import AveragePooling2D,GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "l2RsqLyqkxR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the CNN model \n",
        "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "input_shape = (256, 256, 3)\n",
        "num_classes = 7\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "##############################\n",
        "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "##############################\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyi-zSuZkrYv",
        "outputId": "b14821ef-4a7b-4954-ff1d-7491b7cf1d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_402 (Conv2D)         (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_400 (Ba  (None, 256, 256, 32)     128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_403 (Conv2D)         (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization_401 (Ba  (None, 256, 256, 32)     128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_8 (Averag  (None, 128, 128, 32)     0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv2d_404 (Conv2D)         (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_402 (Ba  (None, 128, 128, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_405 (Conv2D)         (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_403 (Ba  (None, 128, 128, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_9 (Averag  (None, 64, 64, 64)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_406 (Conv2D)         (None, 64, 64, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_404 (Ba  (None, 64, 64, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_10 (Avera  (None, 32, 32, 32)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_407 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_405 (Ba  (None, 32, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_408 (Conv2D)         (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_406 (Ba  (None, 32, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_11 (Avera  (None, 16, 16, 64)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " batch_normalization_407 (Ba  (None, 16384)            65536     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               2097280   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_408 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,305,095\n",
            "Trainable params: 2,271,367\n",
            "Non-trainable params: 33,728\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoedQ0apkUMY",
        "outputId": "1fc8fffe-30cd-40bd-cd44-b6ceceb3737d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "# Define the optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "#optimizer = SGD(lr=0.001, momentum=15, decay=0.0, nesterov=False)\n",
        "# Compile the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVGipb-542cZ"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFMi8eRZMQj-",
        "outputId": "2afd997a-8c80-4415-8f7c-6785e232671c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "99/99 [==============================] - 102s 896ms/step - loss: 1.6530 - accuracy: 0.3826 - val_loss: 1.6301 - val_accuracy: 0.3695\n",
            "Epoch 2/40\n",
            "99/99 [==============================] - 88s 889ms/step - loss: 1.4049 - accuracy: 0.4644 - val_loss: 1.7689 - val_accuracy: 0.3680\n",
            "Epoch 3/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 1.2878 - accuracy: 0.5002 - val_loss: 1.2972 - val_accuracy: 0.5007\n",
            "Epoch 4/40\n",
            "99/99 [==============================] - 88s 886ms/step - loss: 1.2351 - accuracy: 0.5110 - val_loss: 1.2907 - val_accuracy: 0.5278\n",
            "Epoch 5/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 1.1751 - accuracy: 0.5408 - val_loss: 1.1965 - val_accuracy: 0.5649\n",
            "Epoch 6/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 1.1262 - accuracy: 0.5554 - val_loss: 1.2652 - val_accuracy: 0.5321\n",
            "Epoch 7/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 1.0956 - accuracy: 0.5754 - val_loss: 1.1520 - val_accuracy: 0.5606\n",
            "Epoch 8/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 1.0573 - accuracy: 0.5854 - val_loss: 1.0240 - val_accuracy: 0.5763\n",
            "Epoch 9/40\n",
            "99/99 [==============================] - 88s 886ms/step - loss: 1.0301 - accuracy: 0.5964 - val_loss: 1.0066 - val_accuracy: 0.6148\n",
            "Epoch 10/40\n",
            "99/99 [==============================] - 88s 886ms/step - loss: 1.0045 - accuracy: 0.6035 - val_loss: 1.0569 - val_accuracy: 0.5749\n",
            "Epoch 11/40\n",
            "99/99 [==============================] - 88s 884ms/step - loss: 0.9896 - accuracy: 0.6152 - val_loss: 1.0958 - val_accuracy: 0.5792\n",
            "Epoch 12/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 0.9606 - accuracy: 0.6251 - val_loss: 1.1884 - val_accuracy: 0.5606\n",
            "Epoch 13/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 0.9552 - accuracy: 0.6297 - val_loss: 0.9299 - val_accuracy: 0.6077\n",
            "Epoch 14/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 0.9257 - accuracy: 0.6401 - val_loss: 0.9187 - val_accuracy: 0.6163\n",
            "Epoch 15/40\n",
            "99/99 [==============================] - 88s 884ms/step - loss: 0.9132 - accuracy: 0.6439 - val_loss: 0.9935 - val_accuracy: 0.6163\n",
            "Epoch 16/40\n",
            "99/99 [==============================] - 88s 884ms/step - loss: 0.9088 - accuracy: 0.6465 - val_loss: 0.9590 - val_accuracy: 0.6106\n",
            "Epoch 17/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 0.8721 - accuracy: 0.6620 - val_loss: 0.9678 - val_accuracy: 0.5991\n",
            "Epoch 18/40\n",
            "99/99 [==============================] - 88s 884ms/step - loss: 0.8684 - accuracy: 0.6657 - val_loss: 0.9442 - val_accuracy: 0.6362\n",
            "Epoch 19/40\n",
            "99/99 [==============================] - 88s 884ms/step - loss: 0.8496 - accuracy: 0.6665 - val_loss: 0.8998 - val_accuracy: 0.6434\n",
            "Epoch 20/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 0.8577 - accuracy: 0.6665 - val_loss: 1.0299 - val_accuracy: 0.6405\n",
            "Epoch 21/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 0.8332 - accuracy: 0.6776 - val_loss: 0.8881 - val_accuracy: 0.6391\n",
            "Epoch 22/40\n",
            "99/99 [==============================] - 88s 886ms/step - loss: 0.8270 - accuracy: 0.6814 - val_loss: 0.9867 - val_accuracy: 0.6091\n",
            "Epoch 23/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 0.8153 - accuracy: 0.6875 - val_loss: 0.9517 - val_accuracy: 0.6362\n",
            "Epoch 24/40\n",
            "99/99 [==============================] - 88s 891ms/step - loss: 0.8083 - accuracy: 0.6858 - val_loss: 1.0857 - val_accuracy: 0.5820\n",
            "Epoch 25/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 0.7920 - accuracy: 0.6902 - val_loss: 0.9186 - val_accuracy: 0.6391\n",
            "Epoch 26/40\n",
            "99/99 [==============================] - 88s 888ms/step - loss: 0.7729 - accuracy: 0.7069 - val_loss: 0.7665 - val_accuracy: 0.7090\n",
            "Epoch 27/40\n",
            "99/99 [==============================] - 88s 887ms/step - loss: 0.7654 - accuracy: 0.7012 - val_loss: 0.9300 - val_accuracy: 0.6405\n",
            "Epoch 28/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.7593 - accuracy: 0.7050 - val_loss: 0.8264 - val_accuracy: 0.6591\n",
            "Epoch 29/40\n",
            "99/99 [==============================] - 88s 891ms/step - loss: 0.7514 - accuracy: 0.7117 - val_loss: 0.7866 - val_accuracy: 0.6790\n",
            "Epoch 30/40\n",
            "99/99 [==============================] - 88s 895ms/step - loss: 0.7244 - accuracy: 0.7240 - val_loss: 0.7948 - val_accuracy: 0.6890\n",
            "Epoch 31/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.7307 - accuracy: 0.7186 - val_loss: 0.7853 - val_accuracy: 0.7019\n",
            "Epoch 32/40\n",
            "99/99 [==============================] - 88s 891ms/step - loss: 0.7143 - accuracy: 0.7218 - val_loss: 0.7711 - val_accuracy: 0.6890\n",
            "Epoch 33/40\n",
            "99/99 [==============================] - 88s 890ms/step - loss: 0.7143 - accuracy: 0.7239 - val_loss: 0.8863 - val_accuracy: 0.6662\n",
            "Epoch 34/40\n",
            "99/99 [==============================] - 88s 885ms/step - loss: 0.7220 - accuracy: 0.7250 - val_loss: 0.7338 - val_accuracy: 0.7019\n",
            "Epoch 35/40\n",
            "99/99 [==============================] - 88s 890ms/step - loss: 0.7029 - accuracy: 0.7313 - val_loss: 0.8176 - val_accuracy: 0.6947\n",
            "Epoch 36/40\n",
            "99/99 [==============================] - 88s 890ms/step - loss: 0.6804 - accuracy: 0.7469 - val_loss: 0.9845 - val_accuracy: 0.6476\n",
            "Epoch 37/40\n",
            "99/99 [==============================] - 88s 891ms/step - loss: 0.6794 - accuracy: 0.7375 - val_loss: 0.7388 - val_accuracy: 0.7190\n",
            "Epoch 38/40\n",
            "99/99 [==============================] - 88s 890ms/step - loss: 0.6832 - accuracy: 0.7372 - val_loss: 0.7466 - val_accuracy: 0.6876\n",
            "Epoch 39/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6701 - accuracy: 0.7427 - val_loss: 0.8067 - val_accuracy: 0.6919\n",
            "Epoch 40/40\n",
            "99/99 [==============================] - 88s 889ms/step - loss: 0.6531 - accuracy: 0.7529 - val_loss: 0.7371 - val_accuracy: 0.7104\n"
          ]
        }
      ],
      "source": [
        "\n",
        "datagen.fit(x_train)\n",
        "## Fit the model\n",
        "epochs = 40\n",
        "batch_size = 64\n",
        "\n",
        "datagen.fit(x_validate)\n",
        "history = model.fit(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = datagen.flow(x_validate,y_validate))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(xx_train)\n",
        "## Fit the model\n",
        "epochs = 40\n",
        "batch_size = 64\n",
        "\n",
        "datagen.fit(xx_validate)\n",
        "history = model.fit(datagen.flow(xx_train,yy_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = datagen.flow(xx_validate,yy_validate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdzkNtb3buF",
        "outputId": "84fb2031-7645-4feb-8020-51fc87d6fd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "99/99 [==============================] - 89s 898ms/step - loss: 0.8021 - accuracy: 0.6980 - val_loss: 2.6195 - val_accuracy: 0.2910\n",
            "Epoch 2/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.7087 - accuracy: 0.7285 - val_loss: 2.0201 - val_accuracy: 0.3766\n",
            "Epoch 3/40\n",
            "99/99 [==============================] - 89s 894ms/step - loss: 0.6820 - accuracy: 0.7397 - val_loss: 1.0925 - val_accuracy: 0.6063\n",
            "Epoch 4/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6814 - accuracy: 0.7488 - val_loss: 2.5697 - val_accuracy: 0.3937\n",
            "Epoch 5/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6498 - accuracy: 0.7499 - val_loss: 1.2216 - val_accuracy: 0.6134\n",
            "Epoch 6/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6423 - accuracy: 0.7488 - val_loss: 0.7381 - val_accuracy: 0.7161\n",
            "Epoch 7/40\n",
            "99/99 [==============================] - 89s 897ms/step - loss: 0.6373 - accuracy: 0.7532 - val_loss: 1.0743 - val_accuracy: 0.6049\n",
            "Epoch 8/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6281 - accuracy: 0.7569 - val_loss: 1.5494 - val_accuracy: 0.5521\n",
            "Epoch 9/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6314 - accuracy: 0.7540 - val_loss: 2.2415 - val_accuracy: 0.4437\n",
            "Epoch 10/40\n",
            "99/99 [==============================] - 88s 893ms/step - loss: 0.6184 - accuracy: 0.7642 - val_loss: 1.3593 - val_accuracy: 0.5806\n",
            "Epoch 11/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6285 - accuracy: 0.7581 - val_loss: 0.7981 - val_accuracy: 0.7004\n",
            "Epoch 12/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.6038 - accuracy: 0.7656 - val_loss: 0.6956 - val_accuracy: 0.7532\n",
            "Epoch 13/40\n",
            "99/99 [==============================] - 89s 895ms/step - loss: 0.6051 - accuracy: 0.7649 - val_loss: 0.9654 - val_accuracy: 0.6505\n",
            "Epoch 14/40\n",
            "99/99 [==============================] - 88s 893ms/step - loss: 0.5859 - accuracy: 0.7694 - val_loss: 1.3355 - val_accuracy: 0.5920\n",
            "Epoch 15/40\n",
            "99/99 [==============================] - 88s 893ms/step - loss: 0.5922 - accuracy: 0.7683 - val_loss: 3.0349 - val_accuracy: 0.4023\n",
            "Epoch 16/40\n",
            "99/99 [==============================] - 88s 894ms/step - loss: 0.5793 - accuracy: 0.7767 - val_loss: 0.8891 - val_accuracy: 0.6676\n",
            "Epoch 17/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5792 - accuracy: 0.7715 - val_loss: 0.7116 - val_accuracy: 0.7190\n",
            "Epoch 18/40\n",
            "99/99 [==============================] - 89s 895ms/step - loss: 0.5904 - accuracy: 0.7735 - val_loss: 0.9094 - val_accuracy: 0.6748\n",
            "Epoch 19/40\n",
            "99/99 [==============================] - 89s 900ms/step - loss: 0.5759 - accuracy: 0.7748 - val_loss: 0.8156 - val_accuracy: 0.6976\n",
            "Epoch 20/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5642 - accuracy: 0.7800 - val_loss: 2.8289 - val_accuracy: 0.4565\n",
            "Epoch 21/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5697 - accuracy: 0.7800 - val_loss: 1.1386 - val_accuracy: 0.6534\n",
            "Epoch 22/40\n",
            "99/99 [==============================] - 89s 895ms/step - loss: 0.5394 - accuracy: 0.7957 - val_loss: 1.4864 - val_accuracy: 0.5663\n",
            "Epoch 23/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5423 - accuracy: 0.7854 - val_loss: 4.5385 - val_accuracy: 0.3352\n",
            "Epoch 24/40\n",
            "99/99 [==============================] - 88s 894ms/step - loss: 0.5447 - accuracy: 0.7892 - val_loss: 0.6910 - val_accuracy: 0.7461\n",
            "Epoch 25/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5392 - accuracy: 0.7914 - val_loss: 1.8456 - val_accuracy: 0.5335\n",
            "Epoch 26/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5340 - accuracy: 0.7970 - val_loss: 0.7417 - val_accuracy: 0.7247\n",
            "Epoch 27/40\n",
            "99/99 [==============================] - 88s 891ms/step - loss: 0.5319 - accuracy: 0.7897 - val_loss: 3.8990 - val_accuracy: 0.3809\n",
            "Epoch 28/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.5322 - accuracy: 0.7927 - val_loss: 1.5760 - val_accuracy: 0.5735\n",
            "Epoch 29/40\n",
            "99/99 [==============================] - 89s 896ms/step - loss: 0.5223 - accuracy: 0.8008 - val_loss: 1.3712 - val_accuracy: 0.6348\n",
            "Epoch 30/40\n",
            "99/99 [==============================] - 89s 894ms/step - loss: 0.5027 - accuracy: 0.8075 - val_loss: 0.8012 - val_accuracy: 0.7218\n",
            "Epoch 31/40\n",
            "99/99 [==============================] - 89s 894ms/step - loss: 0.5191 - accuracy: 0.7971 - val_loss: 1.1046 - val_accuracy: 0.6405\n",
            "Epoch 32/40\n",
            "99/99 [==============================] - 89s 894ms/step - loss: 0.5049 - accuracy: 0.8067 - val_loss: 1.0002 - val_accuracy: 0.6476\n",
            "Epoch 33/40\n",
            "99/99 [==============================] - 88s 894ms/step - loss: 0.5205 - accuracy: 0.7998 - val_loss: 1.0875 - val_accuracy: 0.6534\n",
            "Epoch 34/40\n",
            "99/99 [==============================] - 89s 894ms/step - loss: 0.4957 - accuracy: 0.8078 - val_loss: 3.8246 - val_accuracy: 0.4251\n",
            "Epoch 35/40\n",
            "99/99 [==============================] - 88s 894ms/step - loss: 0.4748 - accuracy: 0.8181 - val_loss: 1.4061 - val_accuracy: 0.6006\n",
            "Epoch 36/40\n",
            "99/99 [==============================] - 89s 895ms/step - loss: 0.4772 - accuracy: 0.8109 - val_loss: 2.9346 - val_accuracy: 0.4479\n",
            "Epoch 37/40\n",
            "99/99 [==============================] - 89s 895ms/step - loss: 0.4940 - accuracy: 0.8094 - val_loss: 3.8074 - val_accuracy: 0.3923\n",
            "Epoch 38/40\n",
            "99/99 [==============================] - 88s 894ms/step - loss: 0.4889 - accuracy: 0.8102 - val_loss: 0.8023 - val_accuracy: 0.7161\n",
            "Epoch 39/40\n",
            "99/99 [==============================] - 88s 892ms/step - loss: 0.4954 - accuracy: 0.8127 - val_loss: 0.7123 - val_accuracy: 0.7218\n",
            "Epoch 40/40\n",
            "99/99 [==============================] - 88s 893ms/step - loss: 0.5068 - accuracy: 0.8051 - val_loss: 0.8110 - val_accuracy: 0.7290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmbIkLaEnVn3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import AveragePooling2D,GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc5w2kjaj1Oj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,Add\n",
        "from tensorflow.keras.layers import SeparableConv2D,ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization,MaxPool2D\n",
        "from tensorflow.keras.layers import GlobalAvgPool2D\n",
        "from tensorflow.keras import Model\n",
        "# creating the Conv-Batch Norm block\n",
        "\n",
        "def conv_bn(x, filters, kernel_size, strides=1):\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,\n",
        "               padding='same',\n",
        "               use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBN9uozy41-t",
        "outputId": "f1d362c4-8c81-4272-de63-aaec49acbb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 280, 280, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_409 (Conv2D)            (None, 140, 140, 32  864         ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_409 (Batch  (None, 140, 140, 32  128        ['conv2d_409[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_400 (ReLU)               (None, 140, 140, 32  0           ['batch_normalization_409[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_410 (Conv2D)            (None, 140, 140, 64  18432       ['re_lu_400[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_410 (Batch  (None, 140, 140, 64  256        ['conv2d_410[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_401 (ReLU)               (None, 140, 140, 64  0           ['batch_normalization_410[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d (SeparableCon  (None, 140, 140, 12  8768       ['re_lu_401[0][0]']              \n",
            " v2D)                           8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_411 (Batch  (None, 140, 140, 12  512        ['separable_conv2d[0][0]']       \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " re_lu_402 (ReLU)               (None, 140, 140, 12  0           ['batch_normalization_411[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 140, 140, 12  17536      ['re_lu_402[0][0]']              \n",
            " onv2D)                         8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_411 (Conv2D)            (None, 70, 70, 128)  8192        ['re_lu_401[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_412 (Batch  (None, 140, 140, 12  512        ['separable_conv2d_1[0][0]']     \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_413 (Batch  (None, 70, 70, 128)  512        ['conv2d_411[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 70, 70, 128)  0          ['batch_normalization_412[0][0]']\n",
            "                                                                                                  \n",
            " add (Add)                      (None, 70, 70, 128)  0           ['batch_normalization_413[0][0]',\n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_403 (ReLU)               (None, 70, 70, 128)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (SeparableC  (None, 70, 70, 256)  33920      ['re_lu_403[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_414 (Batch  (None, 70, 70, 256)  1024       ['separable_conv2d_2[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_404 (ReLU)               (None, 70, 70, 256)  0           ['batch_normalization_414[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_3 (SeparableC  (None, 70, 70, 256)  67840      ['re_lu_404[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_412 (Conv2D)            (None, 35, 35, 256)  32768       ['batch_normalization_413[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_415 (Batch  (None, 70, 70, 256)  1024       ['separable_conv2d_3[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_416 (Batch  (None, 35, 35, 256)  1024       ['conv2d_412[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 256)  0          ['batch_normalization_415[0][0]']\n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 35, 35, 256)  0           ['batch_normalization_416[0][0]',\n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_405 (ReLU)               (None, 35, 35, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (SeparableC  (None, 35, 35, 728)  188672     ['re_lu_405[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_417 (Batch  (None, 35, 35, 728)  2912       ['separable_conv2d_4[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_406 (ReLU)               (None, 35, 35, 728)  0           ['batch_normalization_417[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_5 (SeparableC  (None, 35, 35, 728)  536536     ['re_lu_406[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_413 (Conv2D)            (None, 18, 18, 728)  186368      ['batch_normalization_416[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_418 (Batch  (None, 35, 35, 728)  2912       ['separable_conv2d_5[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_419 (Batch  (None, 18, 18, 728)  2912       ['conv2d_413[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 18, 18, 728)  0          ['batch_normalization_418[0][0]']\n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 18, 18, 728)  0           ['batch_normalization_419[0][0]',\n",
            "                                                                  'max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_407 (ReLU)               (None, 18, 18, 728)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_6 (SeparableC  (None, 18, 18, 728)  536536     ['re_lu_407[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_420 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_6[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_408 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_420[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_7 (SeparableC  (None, 18, 18, 728)  536536     ['re_lu_408[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_421 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_7[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_409 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_421[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_8 (SeparableC  (None, 18, 18, 728)  536536     ['re_lu_409[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_422 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_8[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_410 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_422[0][0]']\n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 18, 18, 728)  0           ['add_2[0][0]',                  \n",
            "                                                                  're_lu_410[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_411 (ReLU)               (None, 18, 18, 728)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_9 (SeparableC  (None, 18, 18, 728)  536536     ['re_lu_411[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_423 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_9[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_412 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_423[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_10 (Separable  (None, 18, 18, 728)  536536     ['re_lu_412[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_424 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_10[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_413 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_424[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_11 (Separable  (None, 18, 18, 728)  536536     ['re_lu_413[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_425 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_11[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_414 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_425[0][0]']\n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 18, 18, 728)  0           ['add_3[0][0]',                  \n",
            "                                                                  're_lu_414[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_415 (ReLU)               (None, 18, 18, 728)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_12 (Separable  (None, 18, 18, 728)  536536     ['re_lu_415[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_426 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_12[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_416 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_426[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_13 (Separable  (None, 18, 18, 728)  536536     ['re_lu_416[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_427 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_13[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_417 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_427[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_14 (Separable  (None, 18, 18, 728)  536536     ['re_lu_417[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_428 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_14[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_418 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_428[0][0]']\n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 18, 18, 728)  0           ['add_4[0][0]',                  \n",
            "                                                                  're_lu_418[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_419 (ReLU)               (None, 18, 18, 728)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_15 (Separable  (None, 18, 18, 728)  536536     ['re_lu_419[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_429 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_15[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_420 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_429[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_16 (Separable  (None, 18, 18, 728)  536536     ['re_lu_420[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_430 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_16[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_421 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_430[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_17 (Separable  (None, 18, 18, 728)  536536     ['re_lu_421[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_431 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_17[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_422 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_431[0][0]']\n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 18, 18, 728)  0           ['add_5[0][0]',                  \n",
            "                                                                  're_lu_422[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_423 (ReLU)               (None, 18, 18, 728)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_18 (Separable  (None, 18, 18, 728)  536536     ['re_lu_423[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_432 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_18[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_424 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_432[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_19 (Separable  (None, 18, 18, 728)  536536     ['re_lu_424[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_433 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_19[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_425 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_433[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_20 (Separable  (None, 18, 18, 728)  536536     ['re_lu_425[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_434 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_20[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_426 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_434[0][0]']\n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 18, 18, 728)  0           ['add_6[0][0]',                  \n",
            "                                                                  're_lu_426[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_427 (ReLU)               (None, 18, 18, 728)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_21 (Separable  (None, 18, 18, 728)  536536     ['re_lu_427[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_435 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_21[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_428 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_435[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_22 (Separable  (None, 18, 18, 728)  536536     ['re_lu_428[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_436 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_22[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_429 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_436[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_23 (Separable  (None, 18, 18, 728)  536536     ['re_lu_429[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_437 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_23[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_430 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_437[0][0]']\n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 18, 18, 728)  0           ['add_7[0][0]',                  \n",
            "                                                                  're_lu_430[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_431 (ReLU)               (None, 18, 18, 728)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_24 (Separable  (None, 18, 18, 728)  536536     ['re_lu_431[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_438 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_24[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_432 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_438[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_25 (Separable  (None, 18, 18, 728)  536536     ['re_lu_432[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_439 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_25[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_433 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_439[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_26 (Separable  (None, 18, 18, 728)  536536     ['re_lu_433[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_440 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_26[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_434 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_440[0][0]']\n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 18, 18, 728)  0           ['add_8[0][0]',                  \n",
            "                                                                  're_lu_434[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_435 (ReLU)               (None, 18, 18, 728)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_27 (Separable  (None, 18, 18, 728)  536536     ['re_lu_435[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_441 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_27[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_436 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_441[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_28 (Separable  (None, 18, 18, 728)  536536     ['re_lu_436[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_442 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_28[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_437 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_442[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_29 (Separable  (None, 18, 18, 728)  536536     ['re_lu_437[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_443 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_29[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_438 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_443[0][0]']\n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 18, 18, 728)  0           ['add_9[0][0]',                  \n",
            "                                                                  're_lu_438[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_439 (ReLU)               (None, 18, 18, 728)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " separable_conv2d_30 (Separable  (None, 18, 18, 728)  536536     ['re_lu_439[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_444 (Batch  (None, 18, 18, 728)  2912       ['separable_conv2d_30[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_440 (ReLU)               (None, 18, 18, 728)  0           ['batch_normalization_444[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_31 (Separable  (None, 18, 18, 1024  752024     ['re_lu_440[0][0]']              \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_414 (Conv2D)            (None, 9, 9, 1024)   745472      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_445 (Batch  (None, 18, 18, 1024  4096       ['separable_conv2d_31[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_446 (Batch  (None, 9, 9, 1024)  4096        ['conv2d_414[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 9, 9, 1024)  0           ['batch_normalization_445[0][0]']\n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 9, 9, 1024)   0           ['batch_normalization_446[0][0]',\n",
            "                                                                  'max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " separable_conv2d_32 (Separable  (None, 9, 9, 1536)  1582080     ['add_11[0][0]']                 \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_447 (Batch  (None, 9, 9, 1536)  6144        ['separable_conv2d_32[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu_441 (ReLU)               (None, 9, 9, 1536)   0           ['batch_normalization_447[0][0]']\n",
            "                                                                                                  \n",
            " separable_conv2d_33 (Separable  (None, 9, 9, 2048)  3159552     ['re_lu_441[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_448 (Batch  (None, 9, 9, 2048)  8192        ['separable_conv2d_33[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['batch_normalization_448[0][0]']\n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 512)          1049088     ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 512)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 7)            3591        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,914,159\n",
            "Trainable params: 21,859,631\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#import necessary libraries\n",
        "\n",
        "\n",
        "# creating separableConv-Batch Norm block\n",
        "\n",
        "def sep_bn(x, filters, kernel_size, strides=1):\n",
        "    \n",
        "    x = SeparableConv2D(filters=filters, \n",
        "                        kernel_size = kernel_size, \n",
        "                        strides=strides, \n",
        "                        padding = 'same', \n",
        "                        use_bias = False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "# entry flow\n",
        "\n",
        "def entry_flow(x):\n",
        "    \n",
        "    x = conv_bn(x, filters =32, kernel_size =3, strides=2)\n",
        "    x = ReLU()(x)\n",
        "    x = conv_bn(x, filters =64, kernel_size =3, strides=1)\n",
        "    tensor = ReLU()(x)\n",
        "    \n",
        "    x = sep_bn(tensor, filters = 128, kernel_size =3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 128, kernel_size =3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=128, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=256, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=728, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    return x\n",
        "# middle flow\n",
        "\n",
        "def middle_flow(tensor):\n",
        "    \n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        \n",
        "        tensor = Add()([tensor,x])\n",
        "       \n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        \n",
        "        tensor = Add()([tensor,x])\n",
        "\n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "       \n",
        "        tensor = Add()([tensor,x])\n",
        "        \n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "\n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "        \n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "        \n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "\n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "\n",
        "       \n",
        "        return tensor\n",
        "# exit flow\n",
        "\n",
        "def exit_flow(tensor):\n",
        "    \n",
        "    x = ReLU()(tensor)\n",
        "    x = sep_bn(x, filters = 728,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 1024,  kernel_size=3)\n",
        "    x = MaxPool2D(pool_size = 3, strides = 2, padding ='same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters =1024, kernel_size=1, strides =2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = sep_bn(x, filters = 1536,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 2048,  kernel_size=3)\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    \n",
        "    x = Dense (units = 512, activation = 'relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "    x = Dense(7, activation='softmax')(x)\n",
        "    \n",
        "    return x\n",
        "# model code\n",
        "\n",
        "input = Input(shape = (256,256,3))\n",
        "x = entry_flow(input)\n",
        "x = middle_flow(x)\n",
        "output = exit_flow(x)\n",
        "\n",
        "model1 = Model (inputs=input, outputs=output)\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk2o7W5bO8ck"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "90LL8y7MXU5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUGDYIRMIG9K"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "# Define the optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "#optimizer = SGD(lr=0.001, momentum=15, decay=0.0, nesterov=False)\n",
        "# Compile the model\n",
        "model1.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(xx_train)\n",
        "## Fit the model\n",
        "epochs = 40\n",
        "batch_size = 64\n",
        "\n",
        "datagen.fit(xx_validate)\n",
        "history = model1.fit(datagen.flow(xx_train,yy_train, batch_size=batch_size),verbose = 1,\n",
        "                              epochs = epochs, validation_data = datagen.flow(xx_validate,yy_validate),callbacks=[learning_rate_reduction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiPcLNEzHn_R",
        "outputId": "87ad089e-f934-4de0-88b1-ab8724f662b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "99/99 [==============================] - 101s 941ms/step - loss: 1.5126 - accuracy: 0.4274 - val_loss: 1.9426 - val_accuracy: 0.1555 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "99/99 [==============================] - 92s 919ms/step - loss: 1.2030 - accuracy: 0.5256 - val_loss: 1.9632 - val_accuracy: 0.1555 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "99/99 [==============================] - 91s 909ms/step - loss: 1.1289 - accuracy: 0.5688 - val_loss: 2.0852 - val_accuracy: 0.1569 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "99/99 [==============================] - 91s 911ms/step - loss: 1.0712 - accuracy: 0.5887 - val_loss: 2.6109 - val_accuracy: 0.1412 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "99/99 [==============================] - 92s 921ms/step - loss: 0.9878 - accuracy: 0.6198 - val_loss: 3.4395 - val_accuracy: 0.2981 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "99/99 [==============================] - 91s 914ms/step - loss: 0.9403 - accuracy: 0.6423 - val_loss: 1.3221 - val_accuracy: 0.5578 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "99/99 [==============================] - 91s 916ms/step - loss: 0.8671 - accuracy: 0.6671 - val_loss: 2.0126 - val_accuracy: 0.4265 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "99/99 [==============================] - 91s 911ms/step - loss: 0.8363 - accuracy: 0.6823 - val_loss: 1.7143 - val_accuracy: 0.4893 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.7856 - accuracy: 0.6998\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "99/99 [==============================] - 92s 920ms/step - loss: 0.7856 - accuracy: 0.6998 - val_loss: 3.0744 - val_accuracy: 0.4308 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "99/99 [==============================] - 91s 908ms/step - loss: 0.6951 - accuracy: 0.7340 - val_loss: 0.8424 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 11/40\n",
            "99/99 [==============================] - 92s 921ms/step - loss: 0.6548 - accuracy: 0.7538 - val_loss: 0.9234 - val_accuracy: 0.6933 - lr: 5.0000e-04\n",
            "Epoch 12/40\n",
            "99/99 [==============================] - 92s 921ms/step - loss: 0.6348 - accuracy: 0.7603 - val_loss: 0.8684 - val_accuracy: 0.6776 - lr: 5.0000e-04\n",
            "Epoch 13/40\n",
            "99/99 [==============================] - 91s 915ms/step - loss: 0.6132 - accuracy: 0.7640 - val_loss: 0.8641 - val_accuracy: 0.6976 - lr: 5.0000e-04\n",
            "Epoch 14/40\n",
            "99/99 [==============================] - 91s 915ms/step - loss: 0.6071 - accuracy: 0.7681 - val_loss: 0.9968 - val_accuracy: 0.6705 - lr: 5.0000e-04\n",
            "Epoch 15/40\n",
            "99/99 [==============================] - 92s 922ms/step - loss: 0.5913 - accuracy: 0.7740 - val_loss: 0.7152 - val_accuracy: 0.7104 - lr: 5.0000e-04\n",
            "Epoch 16/40\n",
            "99/99 [==============================] - 91s 910ms/step - loss: 0.5650 - accuracy: 0.7851 - val_loss: 1.0321 - val_accuracy: 0.6690 - lr: 5.0000e-04\n",
            "Epoch 17/40\n",
            "99/99 [==============================] - 91s 914ms/step - loss: 0.5712 - accuracy: 0.7822 - val_loss: 0.7945 - val_accuracy: 0.7290 - lr: 5.0000e-04\n",
            "Epoch 18/40\n",
            "99/99 [==============================] - 91s 912ms/step - loss: 0.5490 - accuracy: 0.7879 - val_loss: 0.9236 - val_accuracy: 0.6961 - lr: 5.0000e-04\n",
            "Epoch 19/40\n",
            "99/99 [==============================] - 91s 917ms/step - loss: 0.5303 - accuracy: 0.7949 - val_loss: 0.7943 - val_accuracy: 0.7161 - lr: 5.0000e-04\n",
            "Epoch 20/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.7979\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "99/99 [==============================] - 90s 907ms/step - loss: 0.5256 - accuracy: 0.7979 - val_loss: 1.4924 - val_accuracy: 0.6120 - lr: 5.0000e-04\n",
            "Epoch 21/40\n",
            "99/99 [==============================] - 92s 921ms/step - loss: 0.4676 - accuracy: 0.8238 - val_loss: 0.6305 - val_accuracy: 0.7746 - lr: 2.5000e-04\n",
            "Epoch 22/40\n",
            "99/99 [==============================] - 90s 906ms/step - loss: 0.4353 - accuracy: 0.8292 - val_loss: 0.5382 - val_accuracy: 0.7960 - lr: 2.5000e-04\n",
            "Epoch 23/40\n",
            "99/99 [==============================] - 92s 920ms/step - loss: 0.4237 - accuracy: 0.8355 - val_loss: 0.5929 - val_accuracy: 0.7974 - lr: 2.5000e-04\n",
            "Epoch 24/40\n",
            "99/99 [==============================] - 90s 904ms/step - loss: 0.3999 - accuracy: 0.8431 - val_loss: 0.6643 - val_accuracy: 0.7646 - lr: 2.5000e-04\n",
            "Epoch 25/40\n",
            "99/99 [==============================] - 90s 904ms/step - loss: 0.4047 - accuracy: 0.8401 - val_loss: 0.5324 - val_accuracy: 0.7846 - lr: 2.5000e-04\n",
            "Epoch 26/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8492\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "99/99 [==============================] - 91s 914ms/step - loss: 0.3885 - accuracy: 0.8492 - val_loss: 0.5619 - val_accuracy: 0.7917 - lr: 2.5000e-04\n",
            "Epoch 27/40\n",
            "99/99 [==============================] - 92s 922ms/step - loss: 0.3471 - accuracy: 0.8684 - val_loss: 0.4847 - val_accuracy: 0.8274 - lr: 1.2500e-04\n",
            "Epoch 28/40\n",
            "99/99 [==============================] - 90s 902ms/step - loss: 0.3322 - accuracy: 0.8712 - val_loss: 0.5247 - val_accuracy: 0.8117 - lr: 1.2500e-04\n",
            "Epoch 29/40\n",
            "99/99 [==============================] - 92s 922ms/step - loss: 0.3174 - accuracy: 0.8749 - val_loss: 0.5816 - val_accuracy: 0.7946 - lr: 1.2500e-04\n",
            "Epoch 30/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8787\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "99/99 [==============================] - 90s 902ms/step - loss: 0.3149 - accuracy: 0.8787 - val_loss: 0.5017 - val_accuracy: 0.8160 - lr: 1.2500e-04\n",
            "Epoch 31/40\n",
            "99/99 [==============================] - 91s 914ms/step - loss: 0.2884 - accuracy: 0.8893 - val_loss: 0.4318 - val_accuracy: 0.8531 - lr: 6.2500e-05\n",
            "Epoch 32/40\n",
            "99/99 [==============================] - 92s 924ms/step - loss: 0.2753 - accuracy: 0.8964 - val_loss: 0.4735 - val_accuracy: 0.8331 - lr: 6.2500e-05\n",
            "Epoch 33/40\n",
            "99/99 [==============================] - 90s 900ms/step - loss: 0.2752 - accuracy: 0.8904 - val_loss: 0.4883 - val_accuracy: 0.8445 - lr: 6.2500e-05\n",
            "Epoch 34/40\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.8987\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "99/99 [==============================] - 91s 912ms/step - loss: 0.2617 - accuracy: 0.8987 - val_loss: 0.4937 - val_accuracy: 0.8374 - lr: 6.2500e-05\n",
            "Epoch 35/40\n",
            "99/99 [==============================] - 90s 902ms/step - loss: 0.2539 - accuracy: 0.9002 - val_loss: 0.4358 - val_accuracy: 0.8488 - lr: 3.1250e-05\n",
            "Epoch 36/40\n",
            "99/99 [==============================] - 91s 911ms/step - loss: 0.2381 - accuracy: 0.9077 - val_loss: 0.4259 - val_accuracy: 0.8545 - lr: 3.1250e-05\n",
            "Epoch 37/40\n",
            "99/99 [==============================] - 90s 908ms/step - loss: 0.2368 - accuracy: 0.9096 - val_loss: 0.4613 - val_accuracy: 0.8459 - lr: 3.1250e-05\n",
            "Epoch 38/40\n",
            "99/99 [==============================] - 91s 915ms/step - loss: 0.2218 - accuracy: 0.9147 - val_loss: 0.4231 - val_accuracy: 0.8588 - lr: 3.1250e-05\n",
            "Epoch 39/40\n",
            "99/99 [==============================] - 90s 904ms/step - loss: 0.2314 - accuracy: 0.9096 - val_loss: 0.4419 - val_accuracy: 0.8374 - lr: 3.1250e-05\n",
            "Epoch 40/40\n",
            "99/99 [==============================] - 92s 925ms/step - loss: 0.2214 - accuracy: 0.9123 - val_loss: 0.4310 - val_accuracy: 0.8474 - lr: 3.1250e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"/content/drive/MyDrive/Xception.h5\")"
      ],
      "metadata": {
        "id": "h_HFN34u4KWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Baseline.h5\")"
      ],
      "metadata": {
        "id": "_8-H3udM4V7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ni0Rpl2N5TM",
        "outputId": "29446f48-faff-442b-ba01-cb4427bf3906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: accuracy = 0.681883  ;  loss_v = 0.798261\n",
            "Test: accuracy = 0.715753  ;  loss = 0.788872\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=0)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_v, accuracy_v = model.evaluate(xx_validate, yy_validate, verbose=0)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AILPoSjIGaq-",
        "outputId": "c2501848-40e0-4e65-8007-44480b7bafa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: accuracy = 0.700428  ;  loss_v = 0.922324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTtEBCU1hZGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6005c2-e694-4603-e81f-80cf96db3df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: accuracy = 0.679224  ;  loss = 0.971437\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(XX_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L90dSixyEaYb"
      },
      "outputs": [],
      "source": [
        "batch_size=32, "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(XX_test, y_test, verbose=0)\n",
        "loss_v, accuracy_v = model.evaluate(xx_validate, yy_validate, verbose=0)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NSPA29QWikL",
        "outputId": "b2d399a0-a09c-4ac7-f107-313873732fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: accuracy = 0.784593  ;  loss_v = 0.569379\n",
            "Test: accuracy = 0.784247  ;  loss = 0.649477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model1.evaluate(XX_test, y_test, verbose=0)\n",
        "loss_v, accuracy_v = model1.evaluate(xx_validate, yy_validate, verbose=0)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_tbN62AXOtC",
        "outputId": "a39c7f1e-44bd-477c-c56f-079f8b9fdab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: accuracy = 0.848787  ;  loss_v = 0.442438\n",
            "Test: accuracy = 0.849886  ;  loss = 0.426350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69sycn2mXO40"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}